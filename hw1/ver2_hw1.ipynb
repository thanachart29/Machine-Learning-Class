{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('credit_card_churn.csv')\n",
    "df = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2', 'CLIENTNUM'], axis=1)\n",
    "cols = df.columns\n",
    "num_data = list(df._get_numeric_data().columns)\n",
    "cat_data = list(set(cols) - set(num_data))\n",
    "num_data.remove('Dependent_count')\n",
    "num_data.remove('Total_Relationship_Count')\n",
    "num_data.remove('Months_Inactive_12_mon')\n",
    "num_data.remove('Contacts_Count_12_mon')\n",
    "cat_data.append('Dependent_count')\n",
    "cat_data.append('Total_Relationship_Count')\n",
    "cat_data.append('Months_Inactive_12_mon')\n",
    "cat_data.append('Contacts_Count_12_mon')\n",
    "num_data_plot = num_data\n",
    "cat_data_plot = cat_data\n",
    "\n",
    "df = df.loc[df['Card_Category'] != 'Platinum']\n",
    "df = df.loc[df['Total_Ct_Chng_Q4_Q1'] <= 1.6]\n",
    "df = df.loc[df['Months_Inactive_12_mon'] >= 1]\n",
    "df = df.loc[df['Months_Inactive_12_mon'] < 6]\n",
    "df = df.loc[df['Customer_Age'] <= 66]\n",
    "df = df.loc[df['Total_Amt_Chng_Q4_Q1'] <= 1.6]\n",
    "df['Credit_Limit'] = np.log10(df['Credit_Limit'])\n",
    "fitted_data, fitted_lambda = stats.boxcox(df['Avg_Open_To_Buy'])\n",
    "df['Avg_Open_To_Buy'] = fitted_data\n",
    "df['Total_Trans_Amt'] = np.log10(df['Total_Trans_Amt'])\n",
    "df['Avg_Utilization_Ratio'] = (df['Avg_Utilization_Ratio'])**(1/2)\n",
    "#sns.histplot(df, x= 'Avg_Open_To_Buy', hue='Attrition_Flag', kde=True)\n",
    "#for i in cols:\n",
    "#    sns.histplot(df, x= i, hue='Attrition_Flag', kde=True)\n",
    "#    plt.show()\n",
    "#    df[i].value_counts()\n",
    "\n",
    "y = df['Attrition_Flag']\n",
    "#x = df.drop(['Attrition_Flag', 'Customer_Age', 'Gender', 'Marital_Status', 'Card_Category', 'Months_on_book'], axis=1)\n",
    "#x = df.drop(['Attrition_Flag'], axis=1)\n",
    "#x = df.drop(['Attrition_Flag', 'Avg_Utilization_Ratio', 'Dependent_count', 'Marital_Status', 'Income_Category', 'Card_Category', 'Months_on_book', 'Total_Relationship_Count', 'Contacts_Count_12_mon', 'Credit_Limit', 'Avg_Open_To_Buy', 'Customer_Age', 'Gender', 'Total_Revolving_Bal', 'Total_Amt_Chng_Q4_Q1'], axis=1)\n",
    "x = df[['Total_Trans_Ct'\n",
    ",'Total_Ct_Chng_Q4_Q1'\n",
    ",'Total_Revolving_Bal'\n",
    ",'Avg_Utilization_Ratio'\n",
    ",'Total_Trans_Amt'\n",
    ",'Contacts_Count_12_mon'\n",
    ",'Months_Inactive_12_mon'\n",
    ",'Total_Relationship_Count'\n",
    ",'Total_Amt_Chng_Q4_Q1']]\n",
    "\n",
    "x = pd.get_dummies(x)\n",
    "y = y.replace(['Existing Customer', 'Attrited Customer'], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = x.values\n",
    "y = y.values\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model with k-fold and tuning hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "_______________precision__________recall__________f1-score\n",
      "_______0_________0.78______________0.63_____________0.7\n",
      "_______1_________0.93______________0.97_____________0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "parameters = {'C':[0.01, 0.1, 1, 10, 100],\n",
    "                'solver':('newton-cg', 'liblinear', 'lbfgs', 'sag', 'saga')}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "kf.get_n_splits(x)\n",
    "precision_0 = []\n",
    "recall_0 = []\n",
    "f1_0 = []\n",
    "\n",
    "precision_1 = []\n",
    "recall_1 = []\n",
    "f1_1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    logisReg = LogisticRegression()\n",
    "    clf = GridSearchCV(logisReg, parameters, scoring='f1', verbose=5, return_train_score=True, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(x_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision_0.append(report['0']['precision'])\n",
    "    recall_0.append(report['0']['recall'])\n",
    "    f1_0.append(report['0']['f1-score'])\n",
    "\n",
    "    precision_1.append(report['1']['precision'])\n",
    "    recall_1.append(report['1']['recall'])\n",
    "    f1_1.append(report['1']['f1-score'])\n",
    "\n",
    "print('_______________precision__________recall__________f1-score')\n",
    "print('_______0_________'+ str(round(np.mean(precision_0), 2)) + '______________' + str(round(np.mean(recall_0), 2)) + '_____________' + str(round(np.mean(f1_0), 2)))\n",
    "print('_______1_________'+ str(round(np.mean(precision_1), 2)) + '______________' + str(round(np.mean(recall_1), 2)) + '_____________' + str(round(np.mean(f1_1), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid search for feature_selection parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "N_FEATURES_OPTIONS = list(range(1, 25,1))\n",
    "C_OPTIONS = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "pca = PCA()\n",
    "k_chi2 = SelectKBest(chi2)\n",
    "k_mutal = SelectKBest(mutual_info_classif)\n",
    "k_anova = SelectKBest()\n",
    "logis_reg = LogisticRegression()\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"reduce_dim\", \"passthrough\"),\n",
    "        (\"classify\", logis_reg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"reduce_dim\": [pca],\n",
    "        \"reduce_dim__n_components\": N_FEATURES_OPTIONS,\n",
    "        \"classify__C\": C_OPTIONS,\n",
    "        \"classify__solver\":('newton-cg', 'liblinear', 'sag', 'saga')\n",
    "    },\n",
    "    {\n",
    "        \"reduce_dim\": [k_chi2, k_mutal, k_anova],\n",
    "        \"reduce_dim__k\": N_FEATURES_OPTIONS,\n",
    "        \"classify__C\": C_OPTIONS,\n",
    "        \"classify__solver\":('newton-cg', 'liblinear', 'sag', 'saga')\n",
    "    },\n",
    "]\n",
    "reducer_labels = [\"PCA\", \"KBest(chi2)\", \"KBest(Mutual)\", \"KBest(Anova)\"]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "kf.get_n_splits(x)\n",
    "precision_0 = []\n",
    "recall_0 = []\n",
    "f1_0 = []\n",
    "\n",
    "precision_1 = []\n",
    "recall_1 = []\n",
    "f1_1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    grid = GridSearchCV(pipe, n_jobs=-1, param_grid=param_grid, scoring='f1')\n",
    "    grid.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = grid.predict(x_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision_0.append(report['0']['precision'])\n",
    "    recall_0.append(report['0']['recall'])\n",
    "    f1_0.append(report['0']['f1-score'])\n",
    "\n",
    "    precision_1.append(report['1']['precision'])\n",
    "    recall_1.append(report['1']['recall'])\n",
    "    f1_1.append(report['1']['f1-score'])\n",
    "\n",
    "    mean_scores = np.array(grid.cv_results_[\"mean_test_score\"])\n",
    "    # scores are in the order of param_grid iteration, which is alphabetical\n",
    "    mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "    # select score for best C\n",
    "    mean_scores = mean_scores.max(axis=0)\n",
    "    bar_offsets = np.arange(len(N_FEATURES_OPTIONS)) * (len(reducer_labels) + 1) + 0.5\n",
    "    \n",
    "    plt.figure()\n",
    "    COLORS = \"bgrcmyk\"\n",
    "    for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "        plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "    \n",
    "    plt.title(\"Comparing feature reduction techniques\")\n",
    "    plt.xlabel(\"Reduced number of features\")\n",
    "    plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "    plt.ylabel(\"Digit classification accuracy\")\n",
    "    plt.ylim((0, 1))\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "print('_______________precision__________recall__________f1-score')\n",
    "print('_______0_________'+ str(round(np.mean(precision_0), 2)) + '______________' + str(round(np.mean(recall_0), 2)) + '_____________' + str(round(np.mean(f1_0), 2)))\n",
    "print('_______1_________'+ str(round(np.mean(precision_1), 2)) + '______________' + str(round(np.mean(recall_1), 2)) + '_____________' + str(round(np.mean(f1_1), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "y_score = clf.decision_function(x_test)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('FRA503': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64dadede5b611bea0003f916b3ffa8d6ffd0cb12e9e46b2f5e54ff5aa5c7df92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
