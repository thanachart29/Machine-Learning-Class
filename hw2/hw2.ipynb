{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide by\n",
    "\n",
    "นายธนชาติ เสถียรจารุการ 63340500021 <br>\n",
    "\n",
    "นายพชพล เพชรรัตน์ 63340500036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "#import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "df = df.drop(['duration'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check null of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target\n",
    "The total number of data is 41188 samples devided into\n",
    "- No: 36548 samples\n",
    "<br>\n",
    "\n",
    "- Yes: 4640 samples\n",
    "\n",
    "this means that the dataset is imbalanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['y'].value_counts())\n",
    "plt.figure(figsize = (4,4))\n",
    "sns.histplot(data = df, x = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "num_data = list(df._get_numeric_data().columns)\n",
    "cat_data = list(set(cols) - set(num_data))\n",
    "\n",
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in num_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.histplot(data=df, x=i)\n",
    "    plot_num += 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age\n",
    "    - ages over 60 seem to be the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['age'].value_counts())\n",
    "cut_sample = df.loc[df['age'] > 60]\n",
    "sns.boxplot(data = cut_sample, x = 'y', y = 'age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- campaign\n",
    "    - number of campaign over 20 seem to be the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['campaign'].value_counts())\n",
    "cut_sample = df.loc[df['campaign'] >= 21]\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.boxplot(data = cut_sample, x = 'y', y = 'campaign')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pdays\n",
    "    - replace value 999 to -1\n",
    "    - and pdays value over 15 seem to be the outlier\n",
    "    - group data to 2 categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pdays'] = df['pdays'].replace([999], [-1])\n",
    "print(df['pdays'].value_counts())\n",
    "\n",
    "cut_sample = df.loc[df['pdays'] > 15]\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.boxplot(data = cut_sample, x = 'y', y = 'pdays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- previous\n",
    "    - previous values over 3 seem to be the outlier but most of the sample that has previous values over 3 have target 'yes' i guess it is positive to our model so I decided to keep it\n",
    "    - group data to 2 categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['previous'].value_counts())\n",
    "\n",
    "cut_sample = df.loc[df['previous'] > 3]\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.boxplot(data = cut_sample, x = 'y', y = 'previous')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- emp.var.rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp.var.rate'].value_counts()\n",
    "unique = df['emp.var.rate'].unique()\n",
    "print(sorted(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cons.price.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cons.price.idx'].value_counts()\n",
    "unique = df['cons.price.idx'].unique()\n",
    "print(sorted(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cons.conf.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cons.conf.idx'].value_counts()\n",
    "unique = df['cons.conf.idx'].unique()\n",
    "print(sorted(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- euribor3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['euribor3m'].value_counts()\n",
    "unique = df['euribor3m'].unique()\n",
    "print(sorted(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nr.employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nr.employed'].value_counts()\n",
    "unique = df['nr.employed'].unique()\n",
    "print(sorted(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarize numeric outlier\n",
    "- age values over 60\n",
    "- campaign values over 20\n",
    "- pdays values over 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in cat_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.histplot(data=df, x=i)\n",
    "    plot_num += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- job\n",
    "    - consider to cut unknown job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['job'].value_counts())\n",
    "cut_sample = df.loc[df['job'] == 'unknown']\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.countplot(data = cut_sample, x = 'job', hue = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- poutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['poutcome'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- marital\n",
    "    - consider to cut unknown marital status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['marital'].value_counts())\n",
    "cut_sample = df.loc[df['marital'] == 'unknown']\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.countplot(data = cut_sample, x = 'marital', hue = 'y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- housing\n",
    "    - consider to cut unknown housing data\n",
    "    - change to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['housing'].value_counts())\n",
    "cut_sample = df.loc[df['housing'] == 'unknown']\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.countplot(data = cut_sample, x = 'housing', hue = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- month\n",
    "    - consider to change months categorical to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loan\n",
    "    - consider to cut unknown loan data\n",
    "    - change to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['loan'].value_counts())\n",
    "cut_sample = df.loc[df['loan'] == 'unknown']\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.countplot(data = cut_sample, x = 'loan', hue = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- default\n",
    "    - consider to cut yes data then change to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['default'].value_counts())\n",
    "cut_sample = df.loc[df['default'] == 'yes']\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.countplot(data = cut_sample, x = 'default', hue = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- education\n",
    "    - consider to cut illiterate education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['education'].value_counts())\n",
    "cut_sample = df.loc[df['education'] == 'illiterate']\n",
    "print(cut_sample['y'].value_counts())\n",
    "sns.countplot(data = cut_sample, x = 'education', hue = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- contact\n",
    "    - change to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contact'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarize categorical outlier\n",
    "- cut unknown from job data\n",
    "- cut unknown from marital data\n",
    "- cut unknown from housing data\n",
    "- cut unknown from loan data\n",
    "- cut yes from default data\n",
    "- cut illiterate from education data\n",
    "- change month categorical to numerical\n",
    "- change default data to numerical\n",
    "- change loan data to numerical\n",
    "- change contact data to numerical\n",
    "- change housing data to numerical\n",
    "- change target data to numerical\n",
    "- group previos data\n",
    "- group pdays data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['age'] <= 60]\n",
    "df = df.loc[df['campaign'] <= 20]\n",
    "df = df.loc[df['pdays'] <= 15]\n",
    "df = df.loc[df['job'] != 'unknown']\n",
    "df = df.loc[df['marital'] != 'unknown']\n",
    "df = df.loc[df['housing'] != 'unknown']\n",
    "df = df.loc[df['loan'] != 'unknown']\n",
    "df = df.loc[df['default'] != 'yes']\n",
    "df = df.loc[df['education'] != 'illiterat']\n",
    "df['month'] = df['month'].replace(['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'], list(range(1,13,1)))\n",
    "df['default'] = df['default'].replace(['no', 'unknown'], [0,1])\n",
    "df['loan'] = df['loan'].replace(['no', 'yes'], [0,1])\n",
    "df['housing'] = df['housing'].replace(['no', 'yes'], [0,1])\n",
    "df['contact'] = df['contact'].replace(['telephone', 'cellular'], [0,1])\n",
    "\n",
    "df['y'] = df['y'].replace(['no', 'yes'], [0, 1])\n",
    "\n",
    "##### group data\n",
    "df['pdays'] = df['pdays'].replace(list(range(16)), ([1]*16))\n",
    "df['pdays'] = df['pdays'].replace([-1], (0))\n",
    "df['previous'] = df['previous'].replace(list(range(1,16,1)), ([1]*15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "num_data = list(df._get_numeric_data().columns)\n",
    "cat_data = list(set(cols) - set(num_data))\n",
    "\n",
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in num_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.histplot(data=df, x=i)\n",
    "    plot_num += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correct skewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=1)\n",
    "skewed_data_list = ['age','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "x = df[skewed_data_list].values\n",
    "X_trans = quantile_transformer.fit_transform(x)\n",
    "df[skewed_data_list] = X_trans\n",
    "\n",
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in num_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.histplot(data=df, x=i, kde = True)\n",
    "    plot_num += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in cat_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.countplot(data=df, x=i, hue = 'y')\n",
    "    plot_num += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation between numerical data and target\n",
    "- the following list below has a high correlation with the target\n",
    "    - default\n",
    "    - contact\n",
    "    - pdays\n",
    "    - previous\n",
    "    - emp.var.rate\n",
    "    - cons.price.idx\n",
    "    - euribor3m\n",
    "    - nr.employed\n",
    "\n",
    "<br>\n",
    "\n",
    "- the following list below has a low correlation with target\n",
    "    - age\n",
    "    - housing\n",
    "    - loan\n",
    "    - month\n",
    "    - cons.conf.idx\n",
    "    - campaign\n",
    "\n",
    "<br>\n",
    "\n",
    "- the following pair below has a high correlation between feature we devide into 3 range as below\n",
    "\n",
    "    - range 1: correlation 0.7 - 1\n",
    "        - 0.96: emp.var.rate // nr.employed\n",
    "        - 0.85: emp.var.rate // euribor3m\n",
    "        - 0.84: euribor3m // nr.employed\n",
    "\n",
    "        <br>\n",
    "\n",
    "    - range 2: correlation 0.4 - 0.7\n",
    "        - 0.54: contact // cons.price.idx\n",
    "        - 0.47: pdays // previous\n",
    "        - 0.47: emp.var.rate // cons.price.idx\n",
    "        - 0.44: previous // euribor3m\n",
    "        - 0.42: cons.price.idx // euribor3m\n",
    "        \n",
    "        <br>\n",
    "\n",
    "    - range 3: correlation 0.2 - 0.4\n",
    "        - 0.37: previous // nr.employed\n",
    "        - 0.37: previous // emp.var.rate\n",
    "        - 0.34: cons.prive.idx // nr.employed\n",
    "        - 0.33: contact // month\n",
    "        - 0.31: month // cons.conf.idx\n",
    "        - 0.29: pdays // euribor3m\n",
    "        - 0.22: pdays // nr.employed\n",
    "        - 0.21: contact // previous\n",
    "        - 0.20: age // default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df[num_data]\n",
    "plt.figure(figsize = (16,9))\n",
    "sns.heatmap(round(df.corr(), 2), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using ANOVA to verify correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "x = num_df.iloc[:,:-1]\n",
    "y = num_df['y']\n",
    "anova = SelectKBest(f_classif, k=8)\n",
    "x_new = anova.fit(x,y)\n",
    "\n",
    "col = anova.get_support(indices=True)\n",
    "x_new = x.iloc[:,col]\n",
    "x_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize data that have a high relation to the target\n",
    "    - according to the figure below, it obviously show the separation of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_value_data = ['emp.var.rate', 'cons.price.idx', 'euribor3m', 'nr.employed']\n",
    "select_count_data = ['default', 'contact', 'pdays', 'previous']\n",
    "\n",
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in select_value_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.boxplot(data=df, x='y', y=i)\n",
    "    plot_num += 1\n",
    "plt.show()\n",
    "\n",
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in select_count_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.countplot(data=df, x=i, hue='y')\n",
    "    plot_num += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize data that have a low relation to the target\n",
    "    - according to the figure below the data will distribute on the same level. This is the reason that support the removal of these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_value_data = ['age', 'month', 'cons.conf.idx', 'campaign']\n",
    "cut_count_data = ['housing', 'loan']\n",
    "\n",
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in cut_value_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.boxplot(data=df, x='y', y=i)\n",
    "    plot_num += 1\n",
    "plt.show()\n",
    "\n",
    "plot_num = 1\n",
    "plt.figure(figsize = (15,27))\n",
    "for i in cut_count_data:\n",
    "    ax = plt.subplot(7, 3, plot_num)\n",
    "    sns.countplot(data=df, x=i, hue='y')\n",
    "    plot_num += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loan data seem to be clearly separated but in fact the ratio between target and loan data is the same ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    a = df.loc[df['loan'] == i]\n",
    "    count = a['y'].value_counts().values\n",
    "    percent = (count[1]/(count[0] + count[1])) * 100\n",
    "    print(f\"loan = {i}: {percent:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize data that have a high relation between feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range 1: correlation 0.7 - 1\n",
    "- all of 3 features below have a high correlation to each other\n",
    "    - emp.var.rate\n",
    "    - nr.employed\n",
    "    - euribor3m\n",
    "<br/>\n",
    "<br>\n",
    "\n",
    "- result\n",
    "    - emp.var.rate and nr.employed values are very close to each other\n",
    "    - select euribor3m feature to keep because it has the most correlation values and it more like normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = df, x = 'emp.var.rate', y = 'nr.employed', hue = 'y', height = 4, legend = False)\n",
    "plt.show()\n",
    "##### two data values are very close to each other therefore cut the lower correlation to target feature\n",
    "sns.jointplot(data = df, x = 'emp.var.rate', y = 'euribor3m', hue = 'y', height = 4, legend = False)\n",
    "plt.show()\n",
    "sns.jointplot(data = df, x = 'euribor3m', y = 'nr.employed', hue = 'y', height = 4, legend = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range 2: correlation 0.4 - 0.7\n",
    "- from range 1 we cut feature below\n",
    "    - emp.var.rate\n",
    "    - nr.employed\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- in range 2 will have 4 pair\n",
    "    - contact // cons.price.idx\n",
    "    - pdays // previous\n",
    "    - previous // euribor3m\n",
    "    - cons.price.idx // euribor3m\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- result\n",
    "    - the graph between contact and cons.price.idx was seperate each other but not effect to the target therefore cut cons.price.idx feature because have lower correlation to the target\n",
    "    - the graph between previous and euribor3m seem to be positive to our model we will see the relation of previous, euribor3m and target that separate range of each other\n",
    "    - the graph between cons.price.idx and euribor3m does not obviously show the mathematical function therefore keep both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = df, x = 'contact', y = 'cons.price.idx', hue = 'y')\n",
    "plt.show()\n",
    "sns.countplot(data = df, x = 'previous', hue = 'pdays')\n",
    "plt.show()\n",
    "sns.boxplot(data = df, x = 'previous', y = 'euribor3m', hue = 'y')\n",
    "plt.show()\n",
    "sns.jointplot(data = df, x = 'cons.price.idx', y = 'euribor3m', hue = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range 3: correlation 0.2 - 0.4\n",
    "- from range 1 we cut feature below\n",
    "    - cons.price.idx\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- in range 3 will have 5 pair\n",
    "    - contact // month\n",
    "    - month // cons.conf.idx\n",
    "    - pdays // euribor3m\n",
    "    - contact // previous\n",
    "    - age // default\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- result\n",
    "    - the graph between contact and month separate range from each other but not target so month age data because have lower correlation to the target\n",
    "    - the graph between age and default separate range from each other but not target so cut age data because have lower correlation to the target\n",
    "    - the graph between pdays and euribor3m seem to be positive to the model and also the graph between contact and previous seem to be positive to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = df, x = 'contact', y = 'month', hue = 'y')\n",
    "plt.show()\n",
    "sns.boxplot(data = df, x = 'month', y = 'cons.conf.idx', hue = 'y')\n",
    "plt.show()\n",
    "sns.boxplot(data = df, x = 'pdays', y = 'euribor3m', hue = 'y')\n",
    "plt.show()\n",
    "sns.boxplot(data = df, x = 'contact', y = 'previous', hue = 'y')\n",
    "plt.show()\n",
    "sns.boxplot(data = df, x = 'default', y = 'age', hue = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation between categorical data and target \n",
    "- poutcome_nonexistent, poutcome_success and job_student have correlation to target\n",
    "- other feature have few correlation to target so consider to cut all of them out except poutcome_nonexistent, poutcome_success and job_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df[cat_data]\n",
    "cat_df = pd.get_dummies(cat_df)\n",
    "cat_df['y'] = df['y']\n",
    "plt.figure(figsize = (32,18))\n",
    "sns.heatmap(round(cat_df.corr(),2),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using chi2 to verify correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "x = cat_df.iloc[:,:-1]\n",
    "y = cat_df['y']\n",
    "chi_2 = SelectKBest(chi2, k=3)\n",
    "x_new = chi_2.fit(x,y)\n",
    "\n",
    "col = chi_2.get_support(indices=True)\n",
    "x_new = x.iloc[:,col]\n",
    "x_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "df = df.drop(['duration'], axis=1)\n",
    "df = df.loc[df['age'] <= 60]\n",
    "df = df.loc[df['campaign'] <= 20]\n",
    "df = df.loc[df['pdays'] <= 15]\n",
    "df = df.loc[df['job'] != 'unknown']\n",
    "df = df.loc[df['marital'] != 'unknown']\n",
    "df = df.loc[df['housing'] != 'unknown']\n",
    "df = df.loc[df['loan'] != 'unknown']\n",
    "df = df.loc[df['default'] != 'yes']\n",
    "df = df.loc[df['education'] != 'illiterat']\n",
    "df['month'] = df['month'].replace(['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'], list(range(1,13,1)))\n",
    "df['default'] = df['default'].replace(['no', 'unknown'], [0,1])\n",
    "df['loan'] = df['loan'].replace(['no', 'yes'], [0,1])\n",
    "df['housing'] = df['housing'].replace(['no', 'yes'], [0,1])\n",
    "df['contact'] = df['contact'].replace(['telephone', 'cellular'], [0,1])\n",
    "\n",
    "df['y'] = df['y'].replace(['no', 'yes'], [0, 1])\n",
    "\n",
    "##### group data\n",
    "df['pdays'] = df['pdays'].replace(list(range(16)), ([1]*16))\n",
    "df['pdays'] = df['pdays'].replace([-1], (0))\n",
    "df['previous'] = df['previous'].replace(list(range(1,16,1)), ([1]*15))\n",
    "\n",
    "##### correct skewed data\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=1)\n",
    "skewed_data_list = ['age','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "x = df[skewed_data_list].values\n",
    "X_trans = quantile_transformer.fit_transform(x)\n",
    "df[skewed_data_list] = X_trans\n",
    "\n",
    "x = df.drop(['y'], axis=1)\n",
    "y = df['y']\n",
    "num_data = x.select_dtypes(exclude=\"object\").columns\n",
    "cat_data = x.select_dtypes(include=\"object\").columns\n",
    "#x = pd.get_dummies(x)\n",
    "#x = x.values\n",
    "#y = y.values\n",
    "\n",
    "##### standarization\n",
    "#scaler = StandardScaler()\n",
    "#x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4704 candidates, totalling 47040 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter reduce for estimator Pipeline(steps=[('one_hot', OneHotEncoder()),\n                ('reduce_cat_dim', 'passthrough')]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 668, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\pipeline.py\", line 188, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 54, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\base.py\", line 258, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 271, in set_params\n    self._set_params(\"_transformers\", **kwargs)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 54, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\base.py\", line 258, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\pipeline.py\", line 188, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 54, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\base.py\", line 248, in set_params\n    \"with `estimator.get_params().keys()`.\" % (key, self)\nValueError: Invalid parameter reduce for estimator Pipeline(steps=[('one_hot', OneHotEncoder()),\n                ('reduce_cat_dim', 'passthrough')]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24872\\589971662.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thana\\Desktop\\TheShit\\FRA503\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter reduce for estimator Pipeline(steps=[('one_hot', OneHotEncoder()),\n                ('reduce_cat_dim', 'passthrough')]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "k_chi2 = SelectKBest(chi2)\n",
    "k_mutal = SelectKBest(mutual_info_classif)\n",
    "k_anova = SelectKBest()\n",
    "number_num_feature = list(range(1, 15, 1))\n",
    "number_cat_feature = list(range(1, 29, 1))\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "splitter = [\"best\", \"random\"]\n",
    "\n",
    "num_tran = Pipeline(steps=[(\"reduce_num_dim\", \"passthrough\"), (\"scaler\", StandardScaler())])\n",
    "cat_tran = Pipeline([(\"one_hot\", OneHotEncoder()), (\"reduce_cat_dim\", \"passthrough\")])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_tran, num_data),\n",
    "        (\"cat\", cat_tran, cat_data),\n",
    "    ]\n",
    ")\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classify\", DecisionTreeClassifier(random_state=1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"preprocessor__num__reduce_num_dim\" : [k_mutal, k_anova],\n",
    "        \"preprocessor__num__reduce_num_dim__k\" : number_num_feature,\n",
    "        \"preprocessor__cat__reduce_cat_dim\" : [k_chi2],\n",
    "        \"preprocessor__cat__reduce_cat_dim__k\" : number_cat_feature,\n",
    "        \"classify__criterion\" : criterion,\n",
    "        \"classify__splitter\" : splitter,\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"preprocessor__num__reduce_num_dim\" : [PCA()],\n",
    "        \"preprocessor__num__reduce_num_dim__n_components\" : number_num_feature,\n",
    "        \"preprocessor__cat__reduce_cat_dim\" : [k_chi2],\n",
    "        \"preprocessor__cat__reduce_cat_dim__k\" : number_cat_feature,\n",
    "        \"classify__criterion\" : criterion,\n",
    "        \"classify__splitter\" : splitter,\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, n_jobs = -1, param_grid = param_grid, scoring = 'f1', verbose = 5, cv = 10)\n",
    "grid.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer_labels = [\"PCA\", \"KBest(chi2)\", \"KBest(Mutual)\", \"KBest(Anova)\"]\n",
    "mean_scores = np.array(grid.cv_results_[\"mean_test_score\"])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = np.arange(len(N_FEATURES_OPTIONS)) * (len(reducer_labels) + 1) + 0.5\n",
    "\n",
    "plt.figure()\n",
    "COLORS = \"bgrcmyk\"\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel(\"Reduced number of features\")\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel(\"Digit classification accuracy\")\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('FRA503': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64dadede5b611bea0003f916b3ffa8d6ffd0cb12e9e46b2f5e54ff5aa5c7df92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
