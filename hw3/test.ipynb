{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def removeOutlier(df:pd.DataFrame):\n",
    "    ##### remove outlier\n",
    "    df = df.loc[(df['age'] <= 60) & (df['campaign'] <= 20)]\n",
    "    df['pdays'] = df['pdays'].replace([999], [-1])\n",
    "    df = df.loc[(df['pdays'] <= 15) & \n",
    "                (df['job'] != 'unknown') & \n",
    "                (df['marital'] != 'unknown') & \n",
    "                (df['housing'] != 'unknown') &\n",
    "                (df['loan'] != 'unknown') &\n",
    "                (df['default'] != 'yes') &\n",
    "                (df['education'] != 'illiterat')]\n",
    "    return df\n",
    "\n",
    "def convertNum2Cat(df:pd.DataFrame):\n",
    "    ##### change numerical data to categorical data\n",
    "    df['month'] = df['month'].replace(['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'], list(range(1,13,1)))\n",
    "    df['y'] = df['y'].replace(['no', 'yes'], [0, 1])\n",
    "    return df\n",
    "\n",
    "def groupData(df:pd.DataFrame):\n",
    "    ### group numerical data\n",
    "    ##### pdays\n",
    "    df['pdays'] = df['pdays'].replace(list(range(16)), (['yes']*16))\n",
    "    df['pdays'] = df['pdays'].replace([-1], ('no'))\n",
    "    #### previous\n",
    "    df['previous'] = df['previous'].replace(list(range(1,16,1)), (['yes']*15))\n",
    "    df['previous'] = df['previous'].replace([0], ['no'])\n",
    "    ### group categorical data\n",
    "    ###### education\n",
    "    degree = ['university.degree', 'professional.course']\n",
    "    basic_school = ['high.school', 'basic.9y', 'basic.4y', 'basic.6y', 'unknown']\n",
    "    df['education'] = df['education'].replace(degree, ['yes']*len(degree))\n",
    "    df['education'] = df['education'].replace(basic_school, ['no']*len(basic_school))\n",
    "\n",
    "    ##### job\n",
    "    have_job = ['admin.', 'blue-collar', 'technician', 'services', 'management', 'entrepreneur', 'self-employed', 'housemaid']\n",
    "    no_job = ['retired', 'unemployed', 'student']\n",
    "    df['job'] = df['job'].replace(have_job, ['yes']*len(have_job))\n",
    "    df['job'] = df['job'].replace(no_job, ['no']*len(no_job))\n",
    "\n",
    "    ##### marital\n",
    "    alone = ['single', 'divorced']\n",
    "    not_alone = ['married']\n",
    "    df['marital'] = df['marital'].replace(not_alone, ['yes']*len(not_alone))\n",
    "    df['marital'] = df['marital'].replace(alone, ['no']*len(alone))    \n",
    "    return df\n",
    "    \n",
    "def correctSkewed(df:pd.DataFrame):\n",
    "    ##### correct skewed data\n",
    "    quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=1)\n",
    "    skewed_data_list = ['age','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "    x_skew = df[skewed_data_list].values\n",
    "    X_trans = quantile_transformer.fit_transform(x_skew)\n",
    "    df[skewed_data_list] = X_trans\n",
    "    df_x = df.drop(['y'], axis=1)\n",
    "    df_y = df['y']\n",
    "    return df_x, df_y\n",
    "\n",
    "def preprocess4Search():\n",
    "    df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "    df = df.drop(['duration'], axis=1)\n",
    "    df = removeOutlier(df)\n",
    "    df = convertNum2Cat(df)\n",
    "    df = groupData(df)\n",
    "    df_x, df_y = correctSkewed(df)\n",
    "    \n",
    "    return df_x, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchReduceNum():\n",
    "    df_x, df_y = preprocess4Search()\n",
    "    cols = df_x.columns\n",
    "    num_data = [i for i in cols if (len(df_x[i].unique()) != 2 and df_x[i].dtype != 'object')]\n",
    "    cat_data = list(set(cols) - set(num_data))\n",
    "    num_data = pd.Index(num_data)\n",
    "    cat_data = pd.Index(cat_data)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(df_x, df_y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "    k_chi2 = SelectKBest(chi2)\n",
    "    k_mutal = SelectKBest(mutual_info_classif)\n",
    "    k_anova = SelectKBest()\n",
    "    lst = []\n",
    "    for i in range(1,3,1): ##### max 2 layers\n",
    "        comb = itertools.combinations(range(1,9,1), i) ####### max 8 neuron\n",
    "        for val in comb:\n",
    "            lst.append(val)\n",
    "    ##### Declare model and model parameters\n",
    "    model = MLPClassifier(max_iter=10000, random_state=1, learning_rate='adaptive')\n",
    "    number_num_feature = list(range(1, (len(num_data) + 1), 1))\n",
    "    number_cat_feature = list(range(1, (len(cat_data) + 1), 1))\n",
    "    num_tran = Pipeline(steps=[(\"reduce_num_dim\", \"passthrough\"), (\"scaler\", StandardScaler())])\n",
    "    cat_tran = Pipeline([(\"one_hot\", OneHotEncoder()), (\"reduce_cat_dim\", \"passthrough\")])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_tran, num_data),\n",
    "            (\"cat\", cat_tran, cat_data),\n",
    "        ]\n",
    "    )\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classify\", model),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    param_grid = [\n",
    "        {\n",
    "            \"preprocessor__num__reduce_num_dim\" : [k_anova],\n",
    "            \"preprocessor__num__reduce_num_dim__k\" : number_num_feature,\n",
    "            \"preprocessor__cat__reduce_cat_dim\" : [k_chi2],\n",
    "            \"preprocessor__cat__reduce_cat_dim__k\" : number_cat_feature,\n",
    "            \"classify__hidden_layer_sizes\" : lst,\n",
    "            \"classify__activation\" : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            \"classify__solver\" : ['lbfgs', 'sgd', 'adam']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid = GridSearchCV(pipe, n_jobs = -1, param_grid = param_grid, scoring = 'f1', verbose = 5)\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "    y_pred = grid.predict(x_test)\n",
    "    print(\"Classification report \\n=======================\")\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "    print(\"Confusion matrix \\n=======================\")\n",
    "    #print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "    plt.show()\n",
    "\n",
    "    return grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('FRA503': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64dadede5b611bea0003f916b3ffa8d6ffd0cb12e9e46b2f5e54ff5aa5c7df92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
