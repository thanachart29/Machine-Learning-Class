{"cells":[{"cell_type":"markdown","metadata":{"id":"fS7T3M7ajKS5"},"source":["# Preprocessing Code Example\n","\n","### Part I: Set ups\n","This part includes the imported libraries and dataset. Feel free to change the path of the dataset accordingly."]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1646099820779,"user":{"displayName":"KHANARSA PAISIT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOtiPyB15RCrAFs4TOb-DYyAmLGaUyyTnV4xK=s64","userId":"00253122835342063556"},"user_tz":-420},"id":"E7btxShRYOxy"},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\thana\\Desktop\\TheShit\\FRA503\\class\\week4\n"]}],"source":["import pandas as pd\n","import os\n","import numpy as np\n","import sklearn.preprocessing\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"1UfPWDzhYjMf"},"outputs":[{"data":{"text/plain":[" <=50K    17733\n"," >50K      4963\n","Name: income, dtype: int64"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('adult.data', header = None)\n","df.columns = ['age', 'workclass', 'fnlwgt', 'edu', 'edu-num', 'marital', 'occupation', 'relationship', 'race', 'sex', 'cap-gain', 'cap-loss','hpw','native country','income']\n","a = df.loc[df['workclass'] == ' Private']\n","c = a['income']\n","c.value_counts()"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0                State-gov\n","1         Self-emp-not-inc\n","2                  Private\n","3                  Private\n","4                  Private\n","               ...        \n","32556              Private\n","32557              Private\n","32558              Private\n","32559              Private\n","32560         Self-emp-inc\n","Name: workclass, Length: 32561, dtype: object\n"]}],"source":["workclass_df = df['workclass']\n","print(workclass_df)"]},{"cell_type":"markdown","metadata":{"id":"bd1kDVG5Uig0"},"source":["### Part II: Basic Data Understanding\n","\n","We can look at all values and their counts by using the following code. It is useful to understand all aspect of the dataset."]},{"cell_type":"code","execution_count":53,"metadata":{"id":"WizUsTOUcyM9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index([' Prof-specialty', ' Craft-repair', ' Exec-managerial', ' Adm-clerical',\n","       ' Sales', ' Other-service', ' Machine-op-inspct', ' ?',\n","       ' Transport-moving', ' Handlers-cleaners', ' Farming-fishing',\n","       ' Tech-support', ' Protective-serv', ' Priv-house-serv',\n","       ' Armed-Forces'],\n","      dtype='object')\n"]}],"source":["a = df['occupation'].value_counts()\n","print(a.index)"]},{"cell_type":"markdown","metadata":{"id":"DdjUjjQbU7MM"},"source":["### Part III: Preprocessing\n","\n","The following lines of code show how you can normalize the data. Noted that if you want to normalize only one feature, you need to change the datatype accordingly. \n","\n","You can create a new dataframe with one feature by using old_df[['feature_name']]\n","\n","More info at https://scikit-learn.org/stable/modules/preprocessing.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Icmq9A7idxY2","outputId":"c2d36873-5ae3-45d1-ea99-2210b911f616"},"outputs":[],"source":["df2 = df[['age']]\n","\n","min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n","min_max_scaler.fit_transform(df2)"]},{"cell_type":"markdown","metadata":{"id":"CxiR1WUCVk5P"},"source":["Or you can change from array (df['feature_name']) to numpy array by using np.array()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cv6MFvT2fAw9"},"outputs":[],"source":["x_scaled2=min_max_scaler.fit_transform(np.array(df['age']).reshape(1,-1))\n","print(x_scaled2.shape)"]},{"cell_type":"markdown","metadata":{"id":"PGG1GaOrV_Jm"},"source":["To preform one-hot encoding for categorical feature, you can use the following lines of code.\n","\n","More info at https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npbP22FOgvoG"},"outputs":[],"source":["df3 = df[['edu']]\n","df4 = pd.get_dummies(df3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"-gdX6x5EhlFm","outputId":"0938e8d1-31b4-4162-b348-4742acae11ac"},"outputs":[],"source":["df4.head()"]},{"cell_type":"markdown","metadata":{"id":"CJih5j1sW93J"},"source":["You can also perform feature selection on the whole dataframe.\n","\n","More info at https://scikit-learn.org/stable/modules/feature_selection.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThJPMM5rhmjG"},"outputs":[],"source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","\n","x = df.iloc[:,:-1]    #Split only data\n","y = df.iloc[:,-1]     #Split the target out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBlW-pZyXosf"},"outputs":[],"source":["# We can one-hot encode the dataframe. This line of code will encode only categorical features automatically.\n","x = pd.get_dummies(x)\n","\n","# We then create the feature selector. In this case, we use chi-2 algorithm and we want to choose 4 features (k=4).\n","selector = SelectKBest(chi2, k=4)     #This line creates the selector\n","x_new = selector.fit(x,y)             #This line fits the selector to the dataset, and select the features.\n","\n","# Once we fit the selector, all features are selected and its indices are saved. We can create a new dataframe with those indices.\n","col = selector.get_support(indices=True)   #all indices are saved in col.\n","x_new = x.iloc[:,col]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"CuLLri6pXvUq","outputId":"80030305-92e3-4bc4-cae0-8261b94a8a1d"},"outputs":[],"source":["x_new.head()"]},{"cell_type":"markdown","metadata":{"id":"6gWoQQ1uaS6A"},"source":["You can also perform feature extraction. \n","\n","More info at https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSfR9YFhX_Zi","outputId":"b0def55c-15d0-4c35-8cdb-33d2be1a4720"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","pca = PCA(n_components = 4)           # Create PCA transformer\n","x_pca = pca.fit_transform(x)          # Fit and transform PCA transformer to the dataset\n","\n","print(pca.explained_variance_ratio_)  # This show the variance of each component."]},{"cell_type":"markdown","metadata":{"id":"GFTpu3R1bl8D"},"source":["The array above shows the explained variance of each component. The first element is 0.99511. It means that the first component can explain 99.51% of the dataset already. Thus, it means that we can reduce the dimension of the original dataset to only 1 feature that basically covers 99.51% of the data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"8xKAyBjxa22Q","outputId":"71bc4c05-114d-41ba-dbe6-b0c72196fc05"},"outputs":[],"source":["pd.DataFrame(x_pca).head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_PqfFwDbFQ6"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Preprocessing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.9 ('FRA503': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"vscode":{"interpreter":{"hash":"64dadede5b611bea0003f916b3ffa8d6ffd0cb12e9e46b2f5e54ff5aa5c7df92"}}},"nbformat":4,"nbformat_minor":0}
